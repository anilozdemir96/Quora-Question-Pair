{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS512-Project-final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3FcHdeEAgnr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "47c5c9e2-f0bc-4378-d30f-d5f5efc84f78"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from nltk.tokenize import word_tokenize \n",
        "!pip install krovetzstemmer\n",
        "import krovetzstemmer\n",
        "import nltk\n",
        "nltk.download(\"popular\")\n",
        "from nltk.corpus import stopwords\n",
        "from krovetzstemmer import Stemmer\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "!pip install -q keras\n",
        "import keras\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "print(accelerator)\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: krovetzstemmer in /usr/local/lib/python3.6/dist-packages (0.6)\n",
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZptoJGdBpWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "outputId": "74999b2c-b679-4c5f-b660-3bdf909d6265"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADWS03g3Bp1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=pd.read_csv(\"/content/drive/My Drive/X_TRAIN-QUORA.csv\",index_col=\"Unnamed: 0\")\n",
        "X_test=pd.read_csv(\"/content/drive/My Drive/X_TEST-QUORA.csv\",index_col=\"Unnamed: 0\")\n",
        "y_train=pd.read_csv(\"/content/drive/My Drive/Y_TRAIN-QUORA.csv\",header=None,index_col=0)\n",
        "y_test=pd.read_csv(\"/content/drive/My Drive/Y_TEST-QUORA.csv\",header=None,index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BH95WdnFtNZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b335c1ab-cd80-40d2-e5ab-88e67933cae2"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(353751, 14)\n",
            "(50536, 14)\n",
            "(353751, 1)\n",
            "(50536, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mXoSMiaM283",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "outputId": "8a411a1b-bed2-4ae0-ea94-b5042fdd0e2c"
      },
      "source": [
        "\"\"\"\n",
        "Current Features:\n",
        "\n",
        "#of common unigram (wordshare)\n",
        "shared-tfidf\n",
        "word mover distance\n",
        "q1 freq\n",
        "q2 freq\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nCurrent Features:\\n\\n#of common unigram (wordshare)\\nshared-tfidf\\nword mover distance\\nq1 freq\\nq2 freq\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFgVXgo5ZwBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "outputId": "d8b3c525-f2f1-4b82-9d9c-7dcca6921a98"
      },
      "source": [
        "len(np.array(X_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "353751"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ezpbsje3NOoP",
        "colab_type": "text"
      },
      "source": [
        "#New Features\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Lengths & Difference of lengths & Jaccard Similarity \n",
        "\n",
        "The Jaccard Index, also known as the Jaccard similarity coefficient, is a statistic used in understanding the similarities between sample sets. The measurement emphasizes similarity between finite sample sets, and is formally defined as the size of the intersection divided by the size of the union of the sample sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsnBdemrN-KC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lengthq1_train=[]\n",
        "lengthq2_train=[]\n",
        "lengthq1_test=[]\n",
        "lengthq2_test=[]\n",
        "jaccard_sim_train=[]\n",
        "jaccard_sim_test=[]\n",
        "len_dif_train=[]\n",
        "len_dif_test=[]\n",
        "for i in range(0,len(X_train)):\n",
        "  len1=len(str(X_train.iloc[i,2]).split(\" \"))\n",
        "  len2=len(str(X_train.iloc[i,3]).split(\" \"))\n",
        "  wordshare=(X_train.iloc[i,8])\n",
        "\n",
        "  len_dif=abs(len1-len2)\n",
        "  len_dif_train.append(len_dif)\n",
        "\n",
        "  lengthq1_train.append(len1)\n",
        "  lengthq2_train.append(len2)\n",
        "  jaccard_sim_train.append(wordshare/ (len1+len2-wordshare))\n",
        "\n",
        "for i in range(0,len(X_test)):\n",
        "  len1=len(str(X_test.iloc[i,2]).split(\" \"))\n",
        "  len2=len(str(X_test.iloc[i,3]).split(\" \"))\n",
        "  wordshare=(X_test.iloc[i,8])\n",
        "\n",
        "\n",
        "  len_dif=abs(len1-len2)\n",
        "  len_dif_test.append(len_dif)\n",
        "\n",
        "  lengthq1_test.append(len1)\n",
        "  lengthq2_test.append(len2)\n",
        "  jaccard_sim_test.append(wordshare/ (len1+len2-wordshare))\n",
        "\n",
        "X_train['len_q1']=lengthq1_train\n",
        "X_train['len_q2']=lengthq2_train\n",
        "\n",
        "X_test['len_q1']=lengthq1_test\n",
        "X_test['len_q2']=lengthq1_test\n",
        "\n",
        "X_train['jaccard_sim']=jaccard_sim_train\n",
        "X_test['jaccard_sim']=jaccard_sim_test\n",
        "\n",
        "X_train['len_dif']=len_dif_train\n",
        "X_test['len_dif']=len_dif_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGhMOIHmWeb5",
        "colab_type": "text"
      },
      "source": [
        "Cosine Distance\n",
        "\n",
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHSb72bjP1cb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "outputId": "36a1bdde-75d9-402e-94b1-796cda23b609"
      },
      "source": [
        "import re, math\n",
        "from collections import Counter\n",
        "\n",
        "WORD = re.compile(r'\\w+')\n",
        "\n",
        "def get_cosine(vec1, vec2):\n",
        "     intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "     numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "\n",
        "     sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
        "     sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
        "     denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "\n",
        "     if not denominator:\n",
        "        return 0.0\n",
        "     else:\n",
        "        return float(numerator) / denominator\n",
        "\n",
        "def text_to_vector(text):\n",
        "     words = WORD.findall(text)\n",
        "     return Counter(words)\n",
        "\n",
        "text1 = 'This is a foo bar sentence .'\n",
        "text2 = 'This sentence is similar to a foo bar sentence .'\n",
        "\n",
        "vector1 = text_to_vector(\"anil\")\n",
        "vector2 = text_to_vector(\"anil-se\")\n",
        "\n",
        "cosine = get_cosine(vector1, vector2)\n",
        "\n",
        "print ('Cosine:', cosine)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine: 0.7071067811865475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiUyK2ZbWprJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cos_train=[]\n",
        "cos_test=[]\n",
        "for i in range (0,len(X_train)):\n",
        "  s1=str(X_train.iloc[i,2])\n",
        "  s2=str(X_train.iloc[i,3])\n",
        "  s1 = text_to_vector(s1)\n",
        "  s2 = text_to_vector(s2)\n",
        "  cos=get_cosine(s1, s2)\n",
        "  cos_train.append(cos)\n",
        "for i in range (0,len(X_test)):\n",
        "  s1=str(X_test.iloc[i,2])\n",
        "  s2=str(X_test.iloc[i,3])\n",
        "  s1 = text_to_vector(s1)\n",
        "  s2 = text_to_vector(s2)\n",
        "  cos=get_cosine(s1, s2)\n",
        "  cos_test.append(cos)\n",
        "X_train[\"cosine_distance\"]=cos_train\n",
        "X_test[\"cosine_distance\"]=cos_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUd9EdNtQQSy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "45383f5b-30a4-4df1-e644-196983ccbc3f"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>question1_tokenized</th>\n",
              "      <th>question2_tokenized</th>\n",
              "      <th>question1-stemmed</th>\n",
              "      <th>question2-stemmed</th>\n",
              "      <th>wordShare</th>\n",
              "      <th>common_words</th>\n",
              "      <th>shared-tfidf</th>\n",
              "      <th>WMD</th>\n",
              "      <th>Q1-FREQ</th>\n",
              "      <th>Q2-FREQ</th>\n",
              "      <th>len_q1</th>\n",
              "      <th>len_q2</th>\n",
              "      <th>jaccard_sim</th>\n",
              "      <th>len_dif</th>\n",
              "      <th>cosine_distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>290384</th>\n",
              "      <td>411670</td>\n",
              "      <td>411671</td>\n",
              "      <td>study excellent financial analyst</td>\n",
              "      <td>financial analyst use sql</td>\n",
              "      <td>['study', 'excellent', 'financial', 'analyst']</td>\n",
              "      <td>['financial', 'analysts', 'use', 'sql']</td>\n",
              "      <td>['study', 'excellent', 'financial', 'analyst']</td>\n",
              "      <td>['financial', 'analyst', 'use', 'sql']</td>\n",
              "      <td>2</td>\n",
              "      <td>analyst financial</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.710545</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184897</th>\n",
              "      <td>282382</td>\n",
              "      <td>282383</td>\n",
              "      <td>example subsistence farming</td>\n",
              "      <td>example simple farming tool</td>\n",
              "      <td>['examples', 'subsistence', 'farming']</td>\n",
              "      <td>['examples', 'simple', 'farming', 'tools']</td>\n",
              "      <td>['example', 'subsistence', 'farming']</td>\n",
              "      <td>['example', 'simple', 'farming', 'tool']</td>\n",
              "      <td>2</td>\n",
              "      <td>example farming</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.783249</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.577350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107350</th>\n",
              "      <td>176640</td>\n",
              "      <td>176641</td>\n",
              "      <td>parent wo let choose future job college follow...</td>\n",
              "      <td>pass go appear jee pls suggest best cs college...</td>\n",
              "      <td>['parents', 'wo', 'let', 'choose', 'future', '...</td>\n",
              "      <td>['passed', 'going', 'appear', 'jee', 'pls', 's...</td>\n",
              "      <td>['parent', 'wo', 'let', 'choose', 'future', 'j...</td>\n",
              "      <td>['pass', 'go', 'appear', 'jee', 'pls', 'sugges...</td>\n",
              "      <td>1</td>\n",
              "      <td>college</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.007334</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>14</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>4</td>\n",
              "      <td>0.084515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279787</th>\n",
              "      <td>399275</td>\n",
              "      <td>250080</td>\n",
              "      <td>internal parts computer purpose</td>\n",
              "      <td>internal parts computer system purpose serve</td>\n",
              "      <td>['internal', 'parts', 'computer', 'purpose']</td>\n",
              "      <td>['internal', 'parts', 'computer', 'system', 'p...</td>\n",
              "      <td>['internal', 'parts', 'computer', 'purpose']</td>\n",
              "      <td>['internal', 'parts', 'computer', 'system', 'p...</td>\n",
              "      <td>4</td>\n",
              "      <td>purpose internal parts computer</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.545631</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>2</td>\n",
              "      <td>0.816497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58238</th>\n",
              "      <td>102205</td>\n",
              "      <td>102206</td>\n",
              "      <td>delete amazon account</td>\n",
              "      <td>delete amazon account</td>\n",
              "      <td>['delete', 'amazon', 'account']</td>\n",
              "      <td>['delete', 'amazon', 'account']</td>\n",
              "      <td>['delete', 'amazon', 'account']</td>\n",
              "      <td>['delete', 'amazon', 'account']</td>\n",
              "      <td>3</td>\n",
              "      <td>delete account amazon</td>\n",
              "      <td>0.000172</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259180</th>\n",
              "      <td>374920</td>\n",
              "      <td>374921</td>\n",
              "      <td>power positive thinking</td>\n",
              "      <td>cultivate power positive thinking</td>\n",
              "      <td>['power', 'positive', 'thinking']</td>\n",
              "      <td>['cultivate', 'power', 'positive', 'thinking']</td>\n",
              "      <td>['power', 'positive', 'thinking']</td>\n",
              "      <td>['cultivate', 'power', 'positive', 'thinking']</td>\n",
              "      <td>3</td>\n",
              "      <td>positive power thinking</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>0.506248</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.866025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365841</th>\n",
              "      <td>495977</td>\n",
              "      <td>17978</td>\n",
              "      <td>things new employee know go first day tennant</td>\n",
              "      <td>things new employee know go first day</td>\n",
              "      <td>['things', 'new', 'employees', 'know', 'going'...</td>\n",
              "      <td>['things', 'new', 'employees', 'know', 'going'...</td>\n",
              "      <td>['things', 'new', 'employee', 'know', 'go', 'f...</td>\n",
              "      <td>['things', 'new', 'employee', 'know', 'go', 'f...</td>\n",
              "      <td>7</td>\n",
              "      <td>day know new employee first go things</td>\n",
              "      <td>0.000264</td>\n",
              "      <td>0.311377</td>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.935414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131933</th>\n",
              "      <td>9848</td>\n",
              "      <td>127922</td>\n",
              "      <td>current winning presidential election</td>\n",
              "      <td>bias aside point time think win presidential e...</td>\n",
              "      <td>['currently', 'winning', 'presidential', 'elec...</td>\n",
              "      <td>['biases', 'aside', 'point', 'time', 'think', ...</td>\n",
              "      <td>['current', 'winning', 'presidential', 'electi...</td>\n",
              "      <td>['bias', 'aside', 'point', 'time', 'think', 'w...</td>\n",
              "      <td>2</td>\n",
              "      <td>presidential election</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.710542</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>4</td>\n",
              "      <td>0.353553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146868</th>\n",
              "      <td>231910</td>\n",
              "      <td>231911</td>\n",
              "      <td>movies leading actor become mafia</td>\n",
              "      <td>fix internet connection available problem mobi...</td>\n",
              "      <td>['movies', 'leading', 'actor', 'becomes', 'maf...</td>\n",
              "      <td>['fix', 'internet', 'connection', 'available',...</td>\n",
              "      <td>['movies', 'leading', 'actor', 'become', 'mafia']</td>\n",
              "      <td>['fix', 'internet', 'connection', 'available',...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.892477</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121959</th>\n",
              "      <td>197509</td>\n",
              "      <td>197510</td>\n",
              "      <td>rank cut rohtak medical college state quota</td>\n",
              "      <td>register du state quota neet</td>\n",
              "      <td>['rank', 'cut', 'rohtak', 'medical', 'college'...</td>\n",
              "      <td>['register', 'du', 'state', 'quota', 'neet']</td>\n",
              "      <td>['rank', 'cut', 'rohtak', 'medical', 'college'...</td>\n",
              "      <td>['register', 'du', 'state', 'quota', 'neet']</td>\n",
              "      <td>2</td>\n",
              "      <td>quota state</td>\n",
              "      <td>0.000140</td>\n",
              "      <td>1.115120</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2</td>\n",
              "      <td>0.338062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>353751 rows Ã— 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          qid1    qid2  ... len_dif cosine_distance\n",
              "290384  411670  411671  ...       0        0.500000\n",
              "184897  282382  282383  ...       1        0.577350\n",
              "107350  176640  176641  ...       4        0.084515\n",
              "279787  399275  250080  ...       2        0.816497\n",
              "58238   102205  102206  ...       0        1.000000\n",
              "...        ...     ...  ...     ...             ...\n",
              "259180  374920  374921  ...       1        0.866025\n",
              "365841  495977   17978  ...       1        0.935414\n",
              "131933    9848  127922  ...       4        0.353553\n",
              "146868  231910  231911  ...       4        0.000000\n",
              "121959  197509  197510  ...       2        0.338062\n",
              "\n",
              "[353751 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBDToaLwW3lL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbnNdrUIhDuh",
        "colab_type": "text"
      },
      "source": [
        "Final version of Xtrain and Xtest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4nLRkGchMhg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "ccf6c30c-a3c1-485b-cbe0-d4f8d9ddd77c"
      },
      "source": [
        "X_train.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['qid1', 'qid2', 'question1', 'question2', 'question1_tokenized',\n",
              "       'question2_tokenized', 'question1-stemmed', 'question2-stemmed',\n",
              "       'wordShare', 'common_words', 'shared-tfidf', 'WMD', 'Q1-FREQ',\n",
              "       'Q2-FREQ', 'len_q1', 'len_q2', 'jaccard_sim', 'len_dif',\n",
              "       'cosine_distance'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zayDxsLhGmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=X_train[[\"wordShare\",\"shared-tfidf\",\"WMD\",\"Q1-FREQ\",\"Q2-FREQ\",\"len_q1\",\"len_q2\",\"jaccard_sim\",\"cosine_distance\",\"len_dif\"]]\n",
        "X_test=X_test[[\"wordShare\",\"shared-tfidf\",\"WMD\",\"Q1-FREQ\",\"Q2-FREQ\",\"len_q1\",\"len_q2\",\"jaccard_sim\",\"cosine_distance\",\"len_dif\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8riYR1pJhqh0",
        "colab_type": "text"
      },
      "source": [
        "#Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQqafc41iIac",
        "colab_type": "text"
      },
      "source": [
        "We only have to normalize shared-weight since maximum number is very less we are multiply it by 1000 to get it on 0-1 scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhCITUzzhf_r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "outputId": "f66bbb0f-2172-431e-b052-deb2c4c88628"
      },
      "source": [
        "max(X_train[\"shared-tfidf\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0004067850397186828"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwxIuuqChl8P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "b1ccab6a-32a9-4ee2-afa1-1dda475fa8d5"
      },
      "source": [
        "X_train['shared-tfidf'] = X_train['shared-tfidf'].apply(lambda x: x*1000)\n",
        "X_test['shared-tfidf'] = X_test['shared-tfidf'].apply(lambda x: x*1000)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oatsMr3oiYrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now ready."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBIniJj3iqW2",
        "colab_type": "text"
      },
      "source": [
        "#Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M70SKvCjisI3",
        "colab_type": "text"
      },
      "source": [
        "#Logistic Regression\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14v7gTIiiZf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "57af8a0f-9b4a-4f8f-b570-220f1af9fead"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
        "\n",
        "model_logistic = LogisticRegression()\n",
        "\n",
        "# Create regularization penalty space\n",
        "pen = ['l2']\n",
        "\n",
        "# Create regularization hyperparameter space\n",
        "C = np.logspace(0, 4, 3)\n",
        "\n",
        "# Create hyperparameter options\n",
        "hyperparameters = dict(C=C, penalty=pen)\n",
        "\n",
        "\n",
        "# Create grid search using 5-fold cross validation\n",
        "clf = RandomizedSearchCV(model_logistic, hyperparameters, cv=5, verbose=1)\n",
        "\n",
        "# Fit grid search\n",
        "best_model = clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# View best hyperparameters\n",
        "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
        "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  1.1min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best Penalty: l2\n",
            "Best C: 10000.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tIPe8JKi3QN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "3d231526-d6a1-43eb-c9d8-a58d298a47dd"
      },
      "source": [
        "#USE BEST MODEL TO TRAIN ALL DATA.\n",
        "# Predict target vector\n",
        "prediction=best_model.predict(X_test)\n",
        "\n",
        "a=classification_report(y_test, prediction)\n",
        "b=confusion_matrix(y_test, prediction)\n",
        "\n",
        "print(a)\n",
        "print(b)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.89      0.78     31784\n",
            "           1       0.64      0.32      0.43     18752\n",
            "\n",
            "    accuracy                           0.68     50536\n",
            "   macro avg       0.66      0.61      0.60     50536\n",
            "weighted avg       0.67      0.68      0.65     50536\n",
            "\n",
            "[[28320  3464]\n",
            " [12666  6086]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laL-ECimbHaW",
        "colab_type": "text"
      },
      "source": [
        "Logistic Train Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnmNKidtbKft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "2e390f59-4c44-414f-c6ee-48d1f48f17f7"
      },
      "source": [
        "#USE BEST MODEL TO TRAIN ALL DATA.\n",
        "# Predict target vector\n",
        "prediction=best_model.predict(X_train)\n",
        "\n",
        "a=classification_report(y_train, prediction)\n",
        "b=confusion_matrix(y_train, prediction)\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.85      0.80    223240\n",
            "           1       0.68      0.55      0.61    130511\n",
            "\n",
            "    accuracy                           0.74    353751\n",
            "   macro avg       0.72      0.70      0.71    353751\n",
            "weighted avg       0.73      0.74      0.73    353751\n",
            "\n",
            "[[188918  34322]\n",
            " [ 58150  72361]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SmHx_0fjaIq",
        "colab_type": "text"
      },
      "source": [
        "#Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luugD12NjO9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "0ebd516e-57be-4e66-b3b9-a2f58b6e01cb"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(random_state = 42, verbose =1)\n",
        "from pprint import pprint\n",
        "# Look at parameters used by our current forest\n",
        "print('Parameters currently in use:\\n')\n",
        "pprint(rf.get_params())\n",
        "\n",
        "\n",
        "import pprint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Number of trees in random forest\n",
        "n_estimators = n_estimators = [10,20,30,40,50,60,80,100]\n",
        "\n",
        "# Number of features to consider at every split\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [4,6,8,10]\n",
        "\n",
        "\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_depth': max_depth}\n",
        "rf=RandomForestClassifier()\n",
        "\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "best_rf_model=rf_random.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#best params -> depth None est-> 400\n",
        "\n",
        "# View best hyperparameters\n",
        "print('Best Penalty:', best_rf_model.best_estimator_.get_params()['n_estimators'])\n",
        "print('Best C:', best_rf_model.best_estimator_.get_params()['max_depth'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters currently in use:\n",
            "\n",
            "{'bootstrap': True,\n",
            " 'class_weight': None,\n",
            " 'criterion': 'gini',\n",
            " 'max_depth': None,\n",
            " 'max_features': 'auto',\n",
            " 'max_leaf_nodes': None,\n",
            " 'min_impurity_decrease': 0.0,\n",
            " 'min_impurity_split': None,\n",
            " 'min_samples_leaf': 1,\n",
            " 'min_samples_split': 2,\n",
            " 'min_weight_fraction_leaf': 0.0,\n",
            " 'n_estimators': 'warn',\n",
            " 'n_jobs': None,\n",
            " 'oob_score': False,\n",
            " 'random_state': 42,\n",
            " 'verbose': 1,\n",
            " 'warm_start': False}\n",
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 32 is smaller than n_iter=100. Running 32 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed: 15.4min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:715: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.best_estimator_.fit(X, y, **fit_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best Penalty: 30\n",
            "Best C: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om5CQju5lDp1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "058edbe9-2925-4600-afb0-2fa79f7a4119"
      },
      "source": [
        "#USE BEST MODEL of random forest predict test data\n",
        "# Predict target vector\n",
        "prediction=best_rf_model.predict(X_test)\n",
        "\n",
        "a=classification_report(y_test, prediction)\n",
        "b=confusion_matrix(y_test, prediction)\n",
        "\n",
        "print(a)\n",
        "print(b)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.94      0.80     31784\n",
            "           1       0.76      0.32      0.45     18752\n",
            "\n",
            "    accuracy                           0.71     50536\n",
            "   macro avg       0.73      0.63      0.63     50536\n",
            "weighted avg       0.72      0.71      0.67     50536\n",
            "\n",
            "[[29815  1969]\n",
            " [12666  6086]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8GxyDe2f86J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "90a60022-2f9c-4fa3-b600-93f0e831482d"
      },
      "source": [
        "#Train error\n",
        "\n",
        "#USE BEST MODEL of random forest predict test data\n",
        "# Predict target vector\n",
        "prediction=best_rf_model.predict(X_train)\n",
        "\n",
        "a=classification_report(y_train, prediction)\n",
        "b=confusion_matrix(y_train, prediction)\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85    223240\n",
            "           1       0.79      0.63      0.70    130511\n",
            "\n",
            "    accuracy                           0.80    353751\n",
            "   macro avg       0.80      0.76      0.77    353751\n",
            "weighted avg       0.80      0.80      0.79    353751\n",
            "\n",
            "[[201011  22229]\n",
            " [ 48539  81972]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFCOFrmsnqm_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "08812c7c-9651-4052-b09b-0dfd33161344"
      },
      "source": [
        "import pickle\n",
        "pickle.dump(best_rf_model, open(\"RF-MODEL-QUORA\", 'wb')) # Save RF model\n",
        "pickle.dump(best_model, open(\"LR-MODEL-QUORA\", 'wb')) # save Logistic reg model\n",
        "\n",
        "\"\"\"\n",
        "# load the model from disk\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "result = loaded_model.score(X_test, Y_test)\n",
        "print(result)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# load the model from disk\\nloaded_model = pickle.load(open(filename, 'rb'))\\nresult = loaded_model.score(X_test, Y_test)\\nprint(result)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySN-kcyQo1CK",
        "colab_type": "text"
      },
      "source": [
        "#XGBOOST\n",
        "<br>\n",
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwzhzIRdoh2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "2981ced8-5036-40c9-d233-0937df65a849"
      },
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "xgb_model=xgb.XGBClassifier(learning_rate= 0.01, max_depth = 60, n_estimators= 100)\n",
        "\n",
        "xgb_model.fit(X_train, y_train) \n",
        "\n",
        "prediction_xgb=xgb_model.predict(X_test)\n",
        "a=classification_report(y_test, prediction_xgb)\n",
        "b=confusion_matrix(y_test, prediction_xgb)\n",
        "print(a,b)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.89      0.79     31784\n",
            "           1       0.68      0.41      0.51     18752\n",
            "\n",
            "    accuracy                           0.71     50536\n",
            "   macro avg       0.70      0.65      0.65     50536\n",
            "weighted avg       0.70      0.71      0.69     50536\n",
            " [[28152  3632]\n",
            " [11080  7672]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxnPSRS7z3PO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "c1ab9bab-11fe-435b-d1f7-e92cb1891f50"
      },
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "xgb_model=xgb.XGBClassifier(learning_rate= 0.001, max_depth = 60, n_estimators= 100)\n",
        "\n",
        "xgb_model.fit(X_train, y_train) \n",
        "\n",
        "prediction_xgb=xgb_model.predict(X_test)\n",
        "a=classification_report(y_test, prediction_xgb)\n",
        "b=confusion_matrix(y_test, prediction_xgb)\n",
        "print(a,b)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.87      0.79     31784\n",
            "           1       0.65      0.41      0.51     18752\n",
            "\n",
            "    accuracy                           0.70     50536\n",
            "   macro avg       0.68      0.64      0.65     50536\n",
            "weighted avg       0.69      0.70      0.68     50536\n",
            " [[27667  4117]\n",
            " [10985  7767]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqTgZg4hO0rb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "f13d062b-16fd-46d7-cccf-b76b63bca77d"
      },
      "source": [
        "#Train Error\n",
        "prediction_xgb=xgb_model.predict(X_train)\n",
        "a=classification_report(y_train, prediction_xgb)\n",
        "b=confusion_matrix(y_train, prediction_xgb)\n",
        "print(a,b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.93      0.91    223240\n",
            "           1       0.87      0.81      0.84    130511\n",
            "\n",
            "    accuracy                           0.89    353751\n",
            "   macro avg       0.88      0.87      0.88    353751\n",
            "weighted avg       0.89      0.89      0.89    353751\n",
            " [[207565  15675]\n",
            " [ 24388 106123]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HynRpe3Lk5vN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}